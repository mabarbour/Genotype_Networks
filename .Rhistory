vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
gall.ptoid.measures <- web.measures.Gravel(gall.ptoid.list)
## join the results together and rename the column names
all.measures <- left_join(sim.info, willow.gall.measures, by = "unique.sim") %>%
left_join(., gall.ptoid.measures, by = "unique.sim") %>%
rename(.,
link.density.plant_gall = linkage.density.x,
vulnerability.plant_gall = vulnerability.x,
generality.plant_gall = generality.x,
link.density.gall_ptoid = linkage.density.y,
vulnerability.gall_ptoid = vulnerability.y,
generality.gall_ptoid = generality.y)# %>%
all.measures$total_complexity <- rowMeans(all.measures[ ,c("link.density.plant_gall","link.density.gall_ptoid")], na.rm = TRUE)
## save the results of the simulation as a dataframe.
write.csv(all.measures, "~/Documents/Genotype_Networks/data/food web complexity simulation 5 reps of 100 sims.csv")
gall.ptoid.measures
write.csv(all.measures, "~/Documents/Genotype_Networks/data/food web complexity simulation 5 reps of 100 sims.csv") # it took ~X min to run this simulation
all.measures <- read.csv("~/Documents/Genotype_Networks/data/food web complexity simulation 5 reps of 100 sims.csv")
dim(all.measures)[1] # 2221 unique simulations. 2425 simulations originally run
table(all.measures$genotypes.sampled)
all.measures <- all.measures %>% group_by(df.sim.number)
all.measures
alpha.max <- max(filter(all.measures, genotypes.sampled == 1)$total_complexity, na.rm = TRUE) # maximum complexity in monoculture
alpha.max
all.measures <- read.csv("~/Documents/Genotype_Networks/data/food web complexity simulation 5 reps of 100 sims.csv")
alpha.max <- max(filter(all.measures, genotypes.sampled == 1)$total_complexity, na.rm = TRUE) # maximum complexity in monoculture
alpha <- mean(filter(all.measures, genotypes.sampled == 1)$total_complexity, na.rm = TRUE) # mean complexity in monoculture
alpha.min <- min(filter(all.measures, genotypes.sampled == 1)$total_complexity, na.rm = TRUE)
gamma <- mean(filter(all.measures, genotypes.sampled == 25)$total_complexity)
beta <- gamma - alpha
alpha.contrib <- alpha - alpha.min
beta/(beta + alpha.contrib) # increase in food-web complexity due to distinctiveness of genotypes is 60%
alpha.contrib/(beta + alpha.contrib) # 40%
gamma/alpha
ggplot(all.measures, aes(x = genotypes.sampled, y = total_complexity, group = df.sim.number)) +
geom_point(shape = 1, color = "grey") +
geom_smooth(se = FALSE) +
#geom_line(data = sample.rare.100.sum, aes(x = reps.sampled, y = mean_complexity)) +
theme_classic()
library(ggplot2)
ggplot(all.measures, aes(x = genotypes.sampled, y = total_complexity, group = df.sim.number)) +
geom_point(shape = 1, color = "grey") +
geom_smooth(se = FALSE) +
#geom_line(data = sample.rare.100.sum, aes(x = reps.sampled, y = mean_complexity)) +
theme_classic()
# In order to get an expectation of how my data is behaving, I could randomly shuffle everything and see what patterns I observe. Alternatively, I could create different scenarios to see what is going on (ref notebook). Let's try shuffling things up first...
# PERHAPS BOOTSTRAPPING IS THE WAY TO GO. NEED TO THINK ABOUT THE ASSUMPTIONS BEHIND THIS A BIT MORE.
# bootstrapping relies on one crucial assumption: the data accurately represents the true population...
# add a calculation of functional diversity and see if this has a stronger relationship with food-web complexity.
# Gravel simulation
source('~/Documents/Genotype_Networks/Rscripts/network_management_tree_level.R')
#require(mvabund)
require(bipartite)
require(tidyr)
#require(FD)
## change Genotype * to C for plotting aesthetics
levels(tree_level_interaxn_all_plants_traits_size$Genotype)[1] <- "C"
## data frame of interactions
df.interactions <- tree_level_interaxn_all_plants_traits_size %>%
tbl_df() %>%
filter(Genotype != "U") %>% # never collected any galls and thus gall-ptoid interactions so I removed it from the dataset.
select(Genotype,
willow_vLG = vLG_abund,
willow_rG = rG_abund,
willow_aSG = aSG_abund,
willow_SG = SG_abund,
vLG_Platy, vLG_Mesopol, vLG_Tory, vLG_Eulo, vLG_Mymarid,
rG_Platy, rG_Mesopol, rG_Tory, rG_Eulo, rG_Lestodip,
SG_Platy, aSG_Tory)#,
#Platy_abund, Tory_abund, Mesopol_abund, Eulo_abund, Lestodip_abund, Mymarid_abund)
## Function to sample X replicate plants for each genotype, and then sum up the interactions for each genotype. Sampling is done without replacement to make sure unique plant replicates are sampled.
geno.sample <- function(df, reps){
df.group <- df %>% group_by(Genotype)
tmp <- sample_n(df.group, size = reps, replace = FALSE)
tmp.sum <- tmp %>%
summarise_each(funs(sum)) %>%
mutate(plants.sampled = reps)
}
## Function to sample different levels of genetic variation (i.e. number of genotypes) without replacement. Essentially, this peforms a sample-based rarefaction of the data, where samples correspond to unique genotypes. Note also that this is virtually the same as the "geno.sample" function except this time we are sampling different numbers of genotypes.
diversity.sum <- function(df, number.of.genotypes){
tmp <- sample_n(df, size = number.of.genotypes, replace = FALSE) %>% arrange(Genotype) # arranged so we can later identify and remove duplicate genotype combinations
genotype.combo <- paste(tmp$Genotype, collapse = " ") # track genotypes sampled for each combination
tmp.sum <- tmp %>%
summarise_each(funs(sum)) %>%
mutate(genotypes.sampled = number.of.genotypes,
genotype.combo = genotype.combo) %>%
select(-Genotype)
}
## Sample different levels of genetic variation X times
df.reps <- 40 # replications of data frame for simulation
sim.reps <- 100 # replications of simulation
max.genotypes <- 25 # maximum number of genotypes in simulation
#df.sim <- geno.sample(df.interactions, reps = 4) # data frame for simulation
list.sim.food.web <- list()
for(k in 1:df.reps){
list.sim.food.web[[k]] <- geno.sample(df = df.interactions, reps = 4) # create data frame for simulation
}
df.sim.food.web <- list()
for(k in 1:df.reps){
sim.food.web <- list()
for(i in 1:sim.reps){
food.web <- list()
for(j in 1:max.genotypes){
food.web[[j]] <- diversity.sum(df = list.sim.food.web[[k]], number.of.genotypes = j)
}
sim.food.web[[i]] <- ldply(food.web) %>% mutate(sim.number = i)
#browser()
}
tmp.df.sim.food.web <- ldply(sim.food.web) %>%
mutate(df.sim.number = k)
#browser()
# remove duplicate genotype combinations from the food webs
dups.pos <- which(duplicated(tmp.df.sim.food.web$genotype.combo) == TRUE)
df.sim.food.web[[k]] <- tmp.df.sim.food.web[-dups.pos, ]
}
#sim.food.web <- list()
#for(i in 1:sim.reps){
# food.web <- list()
#for(j in 1:max.genotypes){
# food.web[[j]] <- diversity.sum(df = df.sim, number.of.genotypes = j)
#}
#sim.food.web[[i]] <- ldply(food.web) %>%
# mutate(sim.number = i)
#}
sim.food.web.df <- ldply(df.sim.food.web) %>%
mutate(unique.sim = interaction(df.sim.number, sim.number, genotypes.sampled, sep = "_"))
sim.info <- sim.food.web.df %>%
select(unique.sim, df.sim.number, sim.number, genotypes.sampled, genotype.combo, plants.sampled)
web.df <- sim.food.web.df %>%
select(-genotype.combo, -genotypes.sampled, -df.sim.number, -sim.number, -plants.sampled) %>%
gather(unique.sim, variable)
## split up variable (trophic levels of pairwise interactions) for creating bipartite webs
full.link.split <- colsplit(web.df$variable, "_", names = c("lower","upper"))
full.link.split.df <- cbind(web.df, full.link.split)
## create bipartite food webs for willow-gall and gall-ptoid interactions. This enables me to accurately calculated linkage density.
willow.gall.list <- cast(filter(full.link.split.df, lower == "willow"), lower ~ upper | unique.sim)
gall.ptoid.list <- cast(filter(full.link.split.df, lower != "willow"), lower ~ upper | unique.sim)
## this function calculates weighted linkage density, generality, and vulnerability of bipartite food webs
web.measures.Gravel <- function(web.list){
require(bipartite)
web.list.measures <- list()
unique.sim <- c()
for(i in 1:dim(web.list)){
unique.sim[i] <- names(web.list[i])
tmp.web <- web.list[[i]]
rownames(tmp.web) <- tmp.web$lower
web <- as.matrix.data.frame(tmp.web[ ,-1])
web[is.na(web)] <- 0 # replaces NA with zeros in web, which does not affect the food-web indices I'm interested in.
## calculate linkage density, generality, and vulnerability. Code was taken from 'networklevel' function in bipartite, which for some reason, was incorrectly calculating linkage density, generality, and vulnerability in small webs.
preytot.mat <- matrix(rep(colSums(web), NROW(web)),
NROW(web), byrow = TRUE)
preyprop.mat <- web/preytot.mat
predtot.mat <- matrix(rep(rowSums(web), NCOL(web)),
NROW(web), byrow = FALSE)
predprop.mat <- web/predtot.mat
H_Nk <- apply(preyprop.mat, 2, function(x) -sum(x * log(x), na.rm = TRUE))
H_Pk <- apply(predprop.mat, 1, function(x) -sum(x * log(x), na.rm = TRUE))
n_Nk <- ifelse(colSums(web) != 0, exp(H_Nk), 0)
n_Pk <- ifelse(rowSums(web) != 0, exp(H_Pk), 0)
vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
gall.ptoid.measures <- web.measures.Gravel(gall.ptoid.list)
## join the results together and rename the column names
all.measures <- left_join(sim.info, willow.gall.measures, by = "unique.sim") %>%
left_join(., gall.ptoid.measures, by = "unique.sim") %>%
rename(.,
link.density.plant_gall = linkage.density.x,
vulnerability.plant_gall = vulnerability.x,
generality.plant_gall = generality.x,
link.density.gall_ptoid = linkage.density.y,
vulnerability.gall_ptoid = vulnerability.y,
generality.gall_ptoid = generality.y)# %>%
all.measures$total_complexity <- rowMeans(all.measures[ ,c("link.density.plant_gall","link.density.gall_ptoid")], na.rm = TRUE)
## save the results of the simulation as a dataframe.
write.csv(all.measures, "~/Documents/Genotype_Networks/data/food web complexity simulation 40 reps of 100 sims.csv") # it took ~X min to run this simulation
willow.gall.measures
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
willow.gall.list[[1]]
willow.gall.list
willow.gall.list[[1]]
willow.gall.list[[2]]
willow.gall.list[[3]]
willow.gall.list[[4]]
willow.gall.list[[5]]
willow.gall.list[[6]]
willow.gall.list[[7]]
willow.gall.list[[8]]
willow.gall.list[[9]]
willow.gall.list[[10]]
willow.gall.list[[11]]
willow.gall.list[[12]]
willow.gall.list[[13]]
willow.gall.list[[14]]
willow.gall.list[[15]]
willow.gall.list[[1:15]]
head(willow.gall.list)
willow.gall.list
sum(willow.gall.list[[1]][,-1])
willow.gall.list[[1]]
web.measures.Gravel <- function(web.list){
require(bipartite)
web.list.measures <- list()
unique.sim <- c()
for(i in 1:dim(web.list)){
unique.sim[i] <- names(web.list[i])
tmp.web <- web.list[[i]]
rownames(tmp.web) <- tmp.web$lower
web <- as.matrix.data.frame(tmp.web[ ,-1])
web[is.na(web)] <- 0 # replaces NA with zeros in web, which does not affect the food-web indices I'm interested in.
if(sum(web) == 0){
vulnerability <- 0
generality <- 0
linkage.density <- 0
} else{
## calculate linkage density, generality, and vulnerability. Code was taken from 'networklevel' function in bipartite, which for some reason, was incorrectly calculating linkage density, generality, and vulnerability in small webs.
preytot.mat <- matrix(rep(colSums(web), NROW(web)),
NROW(web), byrow = TRUE)
preyprop.mat <- web/preytot.mat
predtot.mat <- matrix(rep(rowSums(web), NCOL(web)),
NROW(web), byrow = FALSE)
predprop.mat <- web/predtot.mat
H_Nk <- apply(preyprop.mat, 2, function(x) -sum(x * log(x), na.rm = TRUE))
H_Pk <- apply(predprop.mat, 1, function(x) -sum(x * log(x), na.rm = TRUE))
n_Nk <- ifelse(colSums(web) != 0, exp(H_Nk), 0)
n_Pk <- ifelse(rowSums(web) != 0, exp(H_Pk), 0)
vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
}
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
web.measures.Gravel <- function(web.list){
require(bipartite)
web.list.measures <- list()
unique.sim <- c()
for(i in 1:dim(web.list)){
unique.sim[i] <- names(web.list[i])
tmp.web <- web.list[[i]]
rownames(tmp.web) <- tmp.web$lower
web <- as.matrix.data.frame(tmp.web[ ,-1])
web[is.na(web)] <- 0 # replaces NA with zeros in web, which does not affect the food-web indices I'm interested in.
if(sum(web) == 0){
vulnerability <- 0
generality <- 0
linkage.density <- 0
} else{
## calculate linkage density, generality, and vulnerability. Code was taken from 'networklevel' function in bipartite, which for some reason, was incorrectly calculating linkage density, generality, and vulnerability in small webs.
preytot.mat <- matrix(rep(colSums(web), NROW(web)),
NROW(web), byrow = TRUE)
preyprop.mat <- web/preytot.mat
predtot.mat <- matrix(rep(rowSums(web), NCOL(web)),
NROW(web), byrow = FALSE)
predprop.mat <- web/predtot.mat
H_Nk <- apply(preyprop.mat, 2, function(x) -sum(x * log(x), na.rm = TRUE))
H_Pk <- apply(predprop.mat, 1, function(x) -sum(x * log(x), na.rm = TRUE))
n_Nk <- ifelse(colSums(web) != 0, exp(H_Nk), 0)
n_Pk <- ifelse(rowSums(web) != 0, exp(H_Pk), 0)
vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
}
browser()
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
vulnerability
generality
linkage.density
willow_gall <- matrix(c(0,0,0,0), ncol = 4)
matrix(rep(colSums(willow_gall), NROW(willow_gall)),
NROW(willow_gall), byrow = TRUE)
tot <- matrix(rep(colSums(willow_gall), NROW(willow_gall)),
NROW(willow_gall), byrow = TRUE)
willow_gall/tot
matrix
willow.gall.list
## this function calculates weighted linkage density, generality, and vulnerability of bipartite food webs
web.measures.Gravel <- function(web.list){
require(bipartite)
web.list.measures <- list()
unique.sim <- c()
for(i in 1:dim(web.list)){
unique.sim[i] <- names(web.list[i])
tmp.web <- web.list[[i]]
if(tmp.web == NULL){
vulnerability <- 0
generality <- 0
linkage.density <- 0
} else{
rownames(tmp.web) <- tmp.web$lower
web <- as.matrix.data.frame(tmp.web[ ,-1])
web[is.na(web)] <- 0 # replaces NA with zeros in web, which does not affect the food-web indices I'm interested in.
## calculate linkage density, generality, and vulnerability. Code was taken from 'networklevel' function in bipartite, which for some reason, was incorrectly calculating linkage density, generality, and vulnerability in small webs.
preytot.mat <- matrix(rep(colSums(web), NROW(web)),
NROW(web), byrow = TRUE)
preyprop.mat <- web/preytot.mat
predtot.mat <- matrix(rep(rowSums(web), NCOL(web)),
NROW(web), byrow = FALSE)
predprop.mat <- web/predtot.mat
H_Nk <- apply(preyprop.mat, 2, function(x) -sum(x * log(x), na.rm = TRUE))
H_Pk <- apply(predprop.mat, 1, function(x) -sum(x * log(x), na.rm = TRUE))
n_Nk <- ifelse(colSums(web) != 0, exp(H_Nk), 0)
n_Pk <- ifelse(rowSums(web) != 0, exp(H_Pk), 0)
vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
}
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.measures <- web.measures.Gravel(willow.gall.list)
which(willow.gall.list == NULL)
dim(willow.gall.list)
willow.gall.list[!unlist(lapply(willow.gall.list, is.null))]
dim(willow.gall.list)
willow.gall.list.noNULL <- willow.gall.list[!unlist(lapply(willow.gall.list, is.null))]
dim(willow.gall.list.noNULL)
## this function calculates weighted linkage density, generality, and vulnerability of bipartite food webs
web.measures.Gravel <- function(web.list){
require(bipartite)
web.list.measures <- list()
unique.sim <- c()
for(i in 1:dim(web.list)){
unique.sim[i] <- names(web.list[i])
tmp.web <- web.list[[i]]
rownames(tmp.web) <- tmp.web$lower
web <- as.matrix.data.frame(tmp.web[ ,-1])
web[is.na(web)] <- 0 # replaces NA with zeros in web, which does not affect the food-web indices I'm interested in.
## calculate linkage density, generality, and vulnerability. Code was taken from 'networklevel' function in bipartite, which for some reason, was incorrectly calculating linkage density, generality, and vulnerability in small webs.
preytot.mat <- matrix(rep(colSums(web), NROW(web)),
NROW(web), byrow = TRUE)
preyprop.mat <- web/preytot.mat
predtot.mat <- matrix(rep(rowSums(web), NCOL(web)),
NROW(web), byrow = FALSE)
predprop.mat <- web/predtot.mat
H_Nk <- apply(preyprop.mat, 2, function(x) -sum(x * log(x), na.rm = TRUE))
H_Pk <- apply(predprop.mat, 1, function(x) -sum(x * log(x), na.rm = TRUE))
n_Nk <- ifelse(colSums(web) != 0, exp(H_Nk), 0)
n_Pk <- ifelse(rowSums(web) != 0, exp(H_Pk), 0)
vulnerability <- sum(rowSums(web)/sum(web) * n_Pk)
generality <- sum(colSums(web)/sum(web) * n_Nk)
linkage.density <- 0.5 * (vulnerability + generality) # LD_q
web.list.measures[[i]] <- data.frame(linkage.density, vulnerability, generality)
}
web.list.measures.df <- ldply(web.list.measures)
cbind.data.frame(unique.sim, web.list.measures.df)
}
## calculate measures separately for willow-galls and gall-parasitoids.
willow.gall.list.noNULL <- willow.gall.list[!unlist(lapply(willow.gall.list, is.null))] # Remove NULL values from list, which are due to zero interactions being documented
gall.ptoid.list.noNULL <- gall.ptoid.list[!unlist(lapply(gall.ptoid.list, is.null))]
willow.gall.measures <- web.measures.Gravel(willow.gall.list.noNULL)
gall.ptoid.measures <- web.measures.Gravel(gall.ptoid.list.noNULL)
## join the results together and rename the column names
all.measures <- left_join(sim.info, willow.gall.measures, by = "unique.sim") %>%
left_join(., gall.ptoid.measures, by = "unique.sim") %>%
rename(.,
link.density.plant_gall = linkage.density.x,
vulnerability.plant_gall = vulnerability.x,
generality.plant_gall = generality.x,
link.density.gall_ptoid = linkage.density.y,
vulnerability.gall_ptoid = vulnerability.y,
generality.gall_ptoid = generality.y)# %>%
all.measures$total_complexity <- rowMeans(all.measures[ ,c("link.density.plant_gall","link.density.gall_ptoid")], na.rm = TRUE)
## save the results of the simulation as a dataframe.
write.csv(all.measures, "~/Documents/Genotype_Networks/data/food web complexity simulation 40 reps of 100 sims.csv") # it took ~5 min to run this simulation at 5 reps, so perhapse 40 min at 40 reps?
all.measures <- read.csv("~/Documents/Genotype_Networks/data/food web complexity simulation 40 reps of 100 sims.csv")
dim(all.measures)[1] # 2221 unique simulations. 2425 simulations originally run
table(all.measures$genotypes.sampled)
985/40
alpha.summary <- all.measures %>%
filter(genotypes.sampled == 1) %>%
group_by(df.sim.number) %>%
summarise(alpha.mean = mean(total_complexity),
alpha.min = min(total_complexity))
alpha.summary
alpha.summary <- all.measures %>%
filter(genotypes.sampled == 1) %>%
group_by(df.sim.number) %>%
summarise(alpha.mean = mean(total_complexity),
alpha.min = min(total_complexity)) %>%
mutate(alpha.contrib = alpha.mean - alpha.min)
gamma.summary <- all.measures %>%
filter(genotypes.sampled == 25) %>%
group_by(df.sim.number) %>%
summarise(gamma = mean(total_complexity))
gamma.summary
beta.summary <- left_join(alpha.summary, gamma.summary, by = "df.sim.number") %>%
mutate(beta.contrib = gamma - alpha.mean,
total.contrib = gamma - alpha.min)
beta.summary
beta.summary <- left_join(alpha.summary, gamma.summary, by = "df.sim.number") %>%
mutate(beta.contrib = gamma - alpha.mean,
total.contrib = gamma - alpha.min,
beta.%contrib = beta.contrib/total.contrib,
alpha.%contrib = alpha.contrib/total.contrib,
beta.magnitude = gamma/alpha.mean)
beta.summary <- left_join(alpha.summary, gamma.summary, by = "df.sim.number") %>%
mutate(beta.contrib = gamma - alpha.mean,
total.contrib = gamma - alpha.min,
beta.prop.contrib = beta.contrib/total.contrib,
alpha.prop.contrib = alpha.contrib/total.contrib,
beta.magnitude = gamma/alpha.mean)
beta.summary
final.summary <- beta.summary %>%
summarise_each(funs(mean, SD))
final.summary <- beta.summary %>%
summarise_each(funs(mean, sd))
final.summary
beta.summary$alpha.min
final.summary <- beta.summary %>%
filter(alpha.min > 0) %>%
summarise_each(funs(mean, sd))
final.summary
final.summary <- beta.summary %>%
filter(alpha.min > 0) %>%
summarise_each(funs(mean, sd)) %>%
c()
final.summary
final.summary <- beta.summary %>%
filter(alpha.min > 0) %>%
summarise_each(funs(mean, sd)) %>%
select(-df.sim.number_mean, -df.sim.number_sd) %>%
c()
final.summary
beta.summary <- left_join(alpha.summary, gamma.summary, by = "df.sim.number") %>%
mutate(beta.contrib = gamma - alpha.mean,
total.contrib = gamma - alpha.min,
beta.prop.contrib = beta.contrib/total.contrib,
alpha.prop.contrib = alpha.contrib/total.contrib,
beta.magnitude = gamma/alpha.mean,
gamma.magnitude = gamma/alpha.min)
final.summary <- beta.summary %>%
filter(alpha.min > 0) %>%
summarise_each(funs(mean, sd)) %>%
select(-df.sim.number_mean, -df.sim.number_sd) %>%
c()
final.summary
ggplot(all.measures, aes(x = genotypes.sampled, y = total_complexity, group = df.sim.number)) +
geom_point(shape = 1, color = "grey") +
geom_smooth(se = FALSE) +
#geom_line(data = sample.rare.100.sum, aes(x = reps.sampled, y = mean_complexity)) +
theme_classic()
library(ggplot2)
ggplot(all.measures, aes(x = genotypes.sampled, y = total_complexity, group = df.sim.number)) +
geom_point(shape = 1, color = "grey") +
geom_smooth(se = FALSE) +
#geom_line(data = sample.rare.100.sum, aes(x = reps.sampled, y = mean_complexity)) +
theme_classic()
glimpse(all.measures)
summary.data.plots <- all.measures %>%
group_by(df.sim.number, sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean = mean(total_complexity))
summary.data.plots
summary.data.plots <- all.measures %>%
group_by(df.sim.number, sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean = mean(total_complexity)) %>%
group_by(df.sim.number, genotypes.sampled) %>%
summarse(total_complexity_mean.mean = mean(total_complexity_mean))
summary.data.plots <- all.measures %>%
group_by(df.sim.number, sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean = mean(total_complexity)) %>%
group_by(df.sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean.mean = mean(total_complexity_mean))
summary.data.plots
summary.data.plots <- all.measures %>%
group_by(df.sim.number, sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean = mean(total_complexity)) %>%
group_by(df.sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean.mean = mean(total_complexity_mean)) %>%
group_by(genotypes.sampled) %>%
summarise(total_complexity_mean.mean.mean = mean(total_complexity_mean.mean))
summary.data.plots
summary.data.plots <- all.measures %>%
group_by(df.sim.number, sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean = mean(total_complexity, na.rm = TRUE)) %>%
group_by(df.sim.number, genotypes.sampled) %>%
summarise(total_complexity_mean.mean = mean(total_complexity_mean, na.rm = TRUE)) %>%
group_by(genotypes.sampled) %>%
summarise(total_complexity_mean.mean.mean = mean(total_complexity_mean.mean, na.rm = TRUE))
summary.data.plots
summary.data.plots$total_complexity_mean.mean.mean
summary.data.plots$total_complexity_mean.mean.mean[25]/summary.data.plots$total_complexity_mean.mean.mean[1]
final.summary
